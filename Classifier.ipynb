{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic mudule\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Light GBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# custom module\n",
    "from Preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "cp = os.getcwd()\n",
    "train = pd.read_csv(os.path.join(cp,'data/train.csv')).drop(['FLAG_MOBIL','index'], axis=1) # 변수 'FLAG_MOBIL','index' 제거\n",
    "test = pd.read_csv(os.path.join(cp,'data/test.csv')).drop(['FLAG_MOBIL','index'], axis=1) # 변수 'FLAG_MOBIL','index' 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_train(data):\n",
    "    # 데이터 컬럼 타입 설정\n",
    "    # object type\n",
    "    data[['gender','car','reality','income_type','edu_type','family_type','house_type','work_phone','phone','email','occyp_type','credit']] = data[['gender','car','reality','income_type','edu_type','family_type','house_type','work_phone','phone','email','occyp_type']].astype(object)\n",
    "\n",
    "    # float type\n",
    "    data[['child_num','income_total','DAYS_BIRTH','DAYS_EMPLOYED','family_size','begin_month']] = data[['child_num','income_total','DAYS_BIRTH','DAYS_EMPLOYED','family_size','begin_month']].astype(float)\n",
    "    \n",
    "    # dummy variable 생성\n",
    "    # X, y 분리\n",
    "    train_X = pd.get_dummies(data.drop(['credit'],axis=1))\n",
    "    train_y = data['credit'].astype(int)\n",
    "\n",
    "    return train_X, train_y\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_test(data):\n",
    "    \n",
    "    data[['gender','car','reality','income_type','edu_type','family_type','house_type','work_phone','phone','email','occyp_type']] = data[['gender','car','reality','income_type','edu_type','family_type','house_type','work_phone','phone','email','occyp_type']].astype(object)\n",
    "\n",
    "    # float type\n",
    "    data[['child_num','income_total','DAYS_BIRTH','DAYS_EMPLOYED','family_size','begin_month']] = data[['child_num','income_total','DAYS_BIRTH','DAYS_EMPLOYED','family_size','begin_month']].astype(float)\n",
    "    \n",
    "    # dummy variable 생성\n",
    "    # X, y 분리\n",
    "    X = pd.get_dummies(data)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(train_X, train_y):\n",
    "    \n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.3, shuffle=False, random_state=100)\n",
    "    \n",
    "    return np.array(train_X), np.array(valid_X), np.array(train_y), np.array(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = preprocessing_train(train)\n",
    "train_X, valid_X, train_y, valid_y = data_split(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def learning_model(train_X, valid_X, train_y, valid_y):\n",
    "\n",
    "    # 학습 데이터셋 정의.\n",
    "    d_train = lgb.Dataset(train_X, label=train_y) \n",
    "    d_test = lgb.Dataset(valid_X, label = valid_y)\n",
    "\n",
    "    # 파라미터 조정\n",
    "    params = {}\n",
    "    params['learning_rate'] = 0.003\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'multiclass'\n",
    "    params['metric'] = 'multi_logloss'\n",
    "    params['sub_feature'] = 0.5\n",
    "    params['num_leaves'] = 10\n",
    "    params['min_data'] = 50\n",
    "    params['max_depth'] = 10\n",
    "    params['num_class'] = 3\n",
    "\n",
    "    clf = lgb.train(params, d_train, 100, d_test)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 804\n",
      "[LightGBM] [Info] Number of data points in the train set: 18519, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score -2.108312\n",
      "[LightGBM] [Info] Start training from score -1.442434\n",
      "[LightGBM] [Info] Start training from score -0.442847\n",
      "[1]\tvalid_0's multi_logloss: 0.884693\n",
      "[2]\tvalid_0's multi_logloss: 0.884649\n",
      "[3]\tvalid_0's multi_logloss: 0.884608\n",
      "[4]\tvalid_0's multi_logloss: 0.884353\n",
      "[5]\tvalid_0's multi_logloss: 0.883849\n",
      "[6]\tvalid_0's multi_logloss: 0.883811\n",
      "[7]\tvalid_0's multi_logloss: 0.883519\n",
      "[8]\tvalid_0's multi_logloss: 0.883006\n",
      "[9]\tvalid_0's multi_logloss: 0.882498\n",
      "[10]\tvalid_0's multi_logloss: 0.882238\n",
      "[11]\tvalid_0's multi_logloss: 0.88196\n",
      "[12]\tvalid_0's multi_logloss: 0.881705\n",
      "[13]\tvalid_0's multi_logloss: 0.881433\n",
      "[14]\tvalid_0's multi_logloss: 0.88119\n",
      "[15]\tvalid_0's multi_logloss: 0.880702\n",
      "[16]\tvalid_0's multi_logloss: 0.880464\n",
      "[17]\tvalid_0's multi_logloss: 0.879989\n",
      "[18]\tvalid_0's multi_logloss: 0.879721\n",
      "[19]\tvalid_0's multi_logloss: 0.879452\n",
      "[20]\tvalid_0's multi_logloss: 0.878988\n",
      "[21]\tvalid_0's multi_logloss: 0.878723\n",
      "[22]\tvalid_0's multi_logloss: 0.878487\n",
      "[23]\tvalid_0's multi_logloss: 0.878265\n",
      "[24]\tvalid_0's multi_logloss: 0.877826\n",
      "[25]\tvalid_0's multi_logloss: 0.877785\n",
      "[26]\tvalid_0's multi_logloss: 0.877538\n",
      "[27]\tvalid_0's multi_logloss: 0.877096\n",
      "[28]\tvalid_0's multi_logloss: 0.876665\n",
      "[29]\tvalid_0's multi_logloss: 0.876453\n",
      "[30]\tvalid_0's multi_logloss: 0.876026\n",
      "[31]\tvalid_0's multi_logloss: 0.875601\n",
      "[32]\tvalid_0's multi_logloss: 0.875173\n",
      "[33]\tvalid_0's multi_logloss: 0.874744\n",
      "[34]\tvalid_0's multi_logloss: 0.874529\n",
      "[35]\tvalid_0's multi_logloss: 0.874103\n",
      "[36]\tvalid_0's multi_logloss: 0.874082\n",
      "[37]\tvalid_0's multi_logloss: 0.873877\n",
      "[38]\tvalid_0's multi_logloss: 0.873673\n",
      "[39]\tvalid_0's multi_logloss: 0.873252\n",
      "[40]\tvalid_0's multi_logloss: 0.873054\n",
      "[41]\tvalid_0's multi_logloss: 0.872819\n",
      "[42]\tvalid_0's multi_logloss: 0.872597\n",
      "[43]\tvalid_0's multi_logloss: 0.872401\n",
      "[44]\tvalid_0's multi_logloss: 0.872386\n",
      "[45]\tvalid_0's multi_logloss: 0.871997\n",
      "[46]\tvalid_0's multi_logloss: 0.871772\n",
      "[47]\tvalid_0's multi_logloss: 0.87174\n",
      "[48]\tvalid_0's multi_logloss: 0.87134\n",
      "[49]\tvalid_0's multi_logloss: 0.870939\n",
      "[50]\tvalid_0's multi_logloss: 0.870752\n",
      "[51]\tvalid_0's multi_logloss: 0.870372\n",
      "[52]\tvalid_0's multi_logloss: 0.870354\n",
      "[53]\tvalid_0's multi_logloss: 0.870132\n",
      "[54]\tvalid_0's multi_logloss: 0.869746\n",
      "[55]\tvalid_0's multi_logloss: 0.869525\n",
      "[56]\tvalid_0's multi_logloss: 0.86934\n",
      "[57]\tvalid_0's multi_logloss: 0.86913\n",
      "[58]\tvalid_0's multi_logloss: 0.869107\n",
      "[59]\tvalid_0's multi_logloss: 0.869079\n",
      "[60]\tvalid_0's multi_logloss: 0.86887\n",
      "[61]\tvalid_0's multi_logloss: 0.868683\n",
      "[62]\tvalid_0's multi_logloss: 0.868311\n",
      "[63]\tvalid_0's multi_logloss: 0.868275\n",
      "[64]\tvalid_0's multi_logloss: 0.867913\n",
      "[65]\tvalid_0's multi_logloss: 0.867553\n",
      "[66]\tvalid_0's multi_logloss: 0.867534\n",
      "[67]\tvalid_0's multi_logloss: 0.86732\n",
      "[68]\tvalid_0's multi_logloss: 0.867121\n",
      "[69]\tvalid_0's multi_logloss: 0.866906\n",
      "[70]\tvalid_0's multi_logloss: 0.86688\n",
      "[71]\tvalid_0's multi_logloss: 0.866685\n",
      "[72]\tvalid_0's multi_logloss: 0.866329\n",
      "[73]\tvalid_0's multi_logloss: 0.86612\n",
      "[74]\tvalid_0's multi_logloss: 0.866097\n",
      "[75]\tvalid_0's multi_logloss: 0.866074\n",
      "[76]\tvalid_0's multi_logloss: 0.865907\n",
      "[77]\tvalid_0's multi_logloss: 0.865731\n",
      "[78]\tvalid_0's multi_logloss: 0.865523\n",
      "[79]\tvalid_0's multi_logloss: 0.865506\n",
      "[80]\tvalid_0's multi_logloss: 0.865165\n",
      "[81]\tvalid_0's multi_logloss: 0.865139\n",
      "[82]\tvalid_0's multi_logloss: 0.864804\n",
      "[83]\tvalid_0's multi_logloss: 0.864776\n",
      "[84]\tvalid_0's multi_logloss: 0.864756\n",
      "[85]\tvalid_0's multi_logloss: 0.864731\n",
      "[86]\tvalid_0's multi_logloss: 0.864536\n",
      "[87]\tvalid_0's multi_logloss: 0.864339\n",
      "[88]\tvalid_0's multi_logloss: 0.864148\n",
      "[89]\tvalid_0's multi_logloss: 0.863948\n",
      "[90]\tvalid_0's multi_logloss: 0.863779\n",
      "[91]\tvalid_0's multi_logloss: 0.863453\n",
      "[92]\tvalid_0's multi_logloss: 0.863268\n",
      "[93]\tvalid_0's multi_logloss: 0.863252\n",
      "[94]\tvalid_0's multi_logloss: 0.863068\n",
      "[95]\tvalid_0's multi_logloss: 0.862742\n",
      "[96]\tvalid_0's multi_logloss: 0.862715\n",
      "[97]\tvalid_0's multi_logloss: 0.862396\n",
      "[98]\tvalid_0's multi_logloss: 0.862236\n",
      "[99]\tvalid_0's multi_logloss: 0.862219\n",
      "[100]\tvalid_0's multi_logloss: 0.861904\n"
     ]
    }
   ],
   "source": [
    "model = learning_model(train_X, valid_X, train_y, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocessing_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11691949, 0.22609848, 0.65698202],\n",
       "       [0.11963536, 0.22362204, 0.6567426 ],\n",
       "       [0.11926132, 0.22564137, 0.65509731],\n",
       "       ...,\n",
       "       [0.11667745, 0.22320115, 0.6601214 ],\n",
       "       [0.11341521, 0.22511236, 0.66147244],\n",
       "       [0.12476193, 0.23705646, 0.6381816 ]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
